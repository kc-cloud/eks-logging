---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
  labels:
    k8s-app: fluentd-cloudwatch
    #expression /(?<time>\d{2}-[A-Za-z]{3}-\d{4} \d{1,2}:\d{1,2}:\d{1,2}.\d{1,4}) (?<loglevel>[^w]{4,5}) \[(?<thread>.*?)\] (?<logger>.*?) (?<message>.*)/
data:
  fluent.conf: |
    @include containers.conf
    @include nginx.conf
    @include web.conf
    @include app.conf
    <match fluent.**>
      @type null
    </match>
  containers.conf: |
    <source>
      @type tail
      @id in_tail_container_logs
      @label @containers
      path /var/log/containers/*.log
      exclude_path [ "/var/log/containers/nginx*", "/var/log/containers/web-app*" ]
      pos_file /var/log/fluentd-containers.log.pos
      tag k8s
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <label @containers>
      <filter k8s>
        @type kubernetes_metadata
        @id filter_kube_metadata
      </filter>

      <filter k8s>
        @type record_transformer
        @id filter_containers_stream_transformer
        <record>
          stream_name k8s
        </record>
      </filter>

      <match k8s>
        @type cloudwatch_logs
        @id out_cloudwatch_logs_containers
        region "#{ENV.fetch('REGION')}"
        log_group_name "/eks/#{ENV.fetch('CLUSTER_NAME')}/containers"
        log_stream_name_key stream_name
        remove_log_stream_name_key true
        auto_create_stream true
        <buffer>
          flush_interval 5
          chunk_limit_size 2m
          queued_chunks_limit_size 32
          retry_forever true
        </buffer>
      </match>
    </label>
  nginx.conf: |
    <source>
      @type tail
      @id in_tail_nginx_logs
      @label @nginx
      path /var/log/containers/nginx*.log
      pos_file /var/log/nginx.log.pos
      tag ws
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <label @nginx>
      <filter ws>
        @type record_transformer
        @id filter_nginx_stream_transformer
        enable_ruby true
        <record>
          stream_name nginx
        </record>
      </filter>

      <filter ws>
        @type parser
        key_name log
        reserve_data true
        remove_key_name_field true
        emit_invalid_record_to_error false
        <parse>
          @type nginx
          time_format %d/%b/%Y:%H:%M:%S %z
          #31/Dec/2020:20:16:30 +0000]
        </parse>
      </filter>

      <match ws>
        @type cloudwatch_logs
        @id out_cloudwatch_logs_nginx
        region "#{ENV.fetch('REGION')}"
        log_group_name "/eks/#{ENV.fetch('CLUSTER_NAME')}/nginx"
        log_stream_name_key stream_name
        remove_log_stream_name_key true
        auto_create_stream true
        <buffer>
          flush_interval 5
          chunk_limit_size 2m
          queued_chunks_limit_size 32
          retry_forever true
        </buffer>
      </match>
    </label>
  web.conf: |
    <source>
      @type tail
      @id web_app_logs
      @label @web
      path /var/log/containers/web*.log
      pos_file /var/log/web-app.log.pos
      tag log4j
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
      @log_level debug
    </source>

    <label @web>
      <filter log4j>
        @type record_transformer
        @id filter_web_stream_transformer
        <record>
          stream_name web
        </record>
      </filter>

      <filter log4j>
        @type parser
        key_name log
        reserve_data true
        remove_key_name_field true
        emit_invalid_record_to_error false
        <parse>
          @type regexp
          expression /(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}.\d{1,4}) (?<loglevel>[^w]{5})  - (?<message>.*)/
          time_key time
          time_format %Y-%m-%d %H:%M:%S.%N
        </parse>
      </filter>

      <match log4j>
        @type cloudwatch_logs
        @id out_web_app_logs
        region "#{ENV.fetch('REGION')}"
        log_group_name "/eks/#{ENV.fetch('CLUSTER_NAME')}/web"
        log_stream_name_key stream_name
        remove_log_stream_name_key true
        auto_create_stream true
        <buffer>
          flush_interval 5
          chunk_limit_size 2m
          queued_chunks_limit_size 32
          retry_forever true
        </buffer>
      </match>
    </label>
  app.conf: |
    <source>
      @type tail
      @id app_logs
      @label @app
      path /var/log/containers/*deployment*.log
      pos_file /var/log/web-app.log.pos
      tag log4j
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <label @app>
      <filter log4j>
        @type record_transformer
        @id filter_web_stream_transformer
        <record>
          stream_name app
        </record>
      </filter>

      <filter log4j>
        @type parser
        key_name log
        reserve_data true
        remove_key_name_field true
        emit_invalid_record_to_error false
        <parse>
          @type multiline
          format_firstline /^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}.\d{1,4})/
          format1 /^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}.\d{1,4}) (?<loglevel>[^w]{5}) (?<hostname>[\S]+) - \[(?<thread>.*?)\] \((?<guid>.*?) (?<uid>.*?)\) (?<logger>.*?) : (?<message>.*)/
          time_key time
          time_format %Y-%m-%d %H:%M:%S.%N
        </parse>
      </filter>

      <match log4j>
        @type cloudwatch_logs
        @id out_app_logs
        region "#{ENV.fetch('REGION')}"
        log_group_name "/eks/#{ENV.fetch('CLUSTER_NAME')}/app"
        log_stream_name_key stream_name
        remove_log_stream_name_key true
        auto_create_stream true
        <buffer>
          flush_interval 5
          chunk_limit_size 2m
          queued_chunks_limit_size 32
          retry_forever true
        </buffer>
      </match>
    </label>